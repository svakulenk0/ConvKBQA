{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Message-Passing Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "\n",
    "from MPBert_model import MessagePassingBert\n",
    "from utils import adj\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# model configuration\n",
    "model_name = 'bert-base-uncased'\n",
    "num_labels = 1\n",
    "num_entities = 12605  # size of the output layer, i.e., maximum number of entities in the subgraph that are candidate answers\n",
    "adjacencies = [[(3, 2), (4, 1)], [(0, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)]]\n",
    "num_relations = len(adjacencies)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "config = BertConfig.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "model = MessagePassingBert(config, num_entities, num_relations, mp_layer=True)\n",
    "# run model on the GPU\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26])\n",
      "torch.Size([2, 7])\n",
      "tensor(9.1537, grad_fn=<NllLossBackward>) tensor([ 0.0000,  0.2882, -0.1879,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# test inference with a sample input, where input is a question and a predicate label along with the list of edges for this predicate\n",
    "question1 = \"When were Beatles founded?\"\n",
    "output = 1\n",
    "\n",
    "# build input tensors\n",
    "input_ids = torch.tensor([tokenizer.encode(question1)] * num_relations)  # Batch size num_relations\n",
    "labels = torch.tensor([output]).unsqueeze(0)  # Batch size 1\n",
    "indices, relation_mask = adj(adjacencies, num_entities, num_relations)\n",
    "entities = torch.zeros(num_entities, 1)\n",
    "entities[[0, 3]] = 1\n",
    "print(relation_mask.shape)\n",
    "print(input_ids.shape)\n",
    "\n",
    "# run inference\n",
    "outputs = model(input_ids, [indices, relation_mask, entities], labels=labels)\n",
    "loss, logits = outputs[:2]\n",
    "print(loss, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.525114059448242\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model.train()\n",
    "outputs = model(input_ids, [indices, relation_mask, entities], labels=labels)\n",
    "loss = outputs[0]\n",
    "current_loss = loss.item()\n",
    "print(current_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load graph\n",
    "from hdt import HDTDocument, TripleComponentRole\n",
    "from settings import *\n",
    "\n",
    "hdt_file = 'wikidata2018_09_11.hdt'\n",
    "kg = HDTDocument(hdt_path+hdt_file)\n",
    "namespace = 'predef-wikidata2018-09-all'\n",
    "PREFIX_E = 'http://www.wikidata.org/entity/'\n",
    "\n",
    "# prepare to retrieve all adjacent nodes including literals\n",
    "predicates_ids = []\n",
    "kg.configure_hops(1, predicates_ids, namespace, True, False)\n",
    "\n",
    "# load all predicate labels\n",
    "from predicates import properties\n",
    "\n",
    "relationid2label = {}\n",
    "for p in properties['results']['bindings']:\n",
    "    _id = p['property']['value'].split('/')[-1]\n",
    "    label = p['propertyLabel']['value']\n",
    "    relationid2label[_id] = label\n",
    "\n",
    "# print(relationid2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6720 conversations loaded\n",
      "Compiled dataset with 5 samples\n",
      "2240 conversations loaded\n",
      "Compiled dataset with 8 samples\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "train_conversations_path = './data/train_set/train_set_ALL.json'\n",
    "dev_conversations_path = './data/dev_set/dev_set_ALL.json'\n",
    "\n",
    "\n",
    "def lookup_predicate_labels(predicate_ids):\n",
    "    p_labels_map = defaultdict(list)\n",
    "    for p_id in predicate_ids:\n",
    "        p_uri = kg.global_id_to_string(p_id, TripleComponentRole.PREDICATE)\n",
    "        label = p_uri.split('/')[-1]\n",
    "        if label in relationid2label:\n",
    "            label = relationid2label[label]\n",
    "        else:\n",
    "            label = label.split('#')[-1]\n",
    "        p_labels_map[label].append(p_id)\n",
    "    return p_labels_map\n",
    "\n",
    "\n",
    "def check_answer_in_subgraph(conversation, entity_ids):\n",
    "    answer1 = conversation['questions'][0]['answer']\n",
    "    # consider only answers which are entities\n",
    "    if ('www.wikidata.org' in answer1):\n",
    "        answer1_id = kg.string_to_global_id(PREFIX_E+answer1.split('/')[-1], TripleComponentRole.OBJECT)\n",
    "        in_subgraph = answer1_id in entity_ids\n",
    "        # consider only answer entities that are in the subgraph\n",
    "        if in_subgraph:\n",
    "            answer1_idx = entity_ids.index(answer1_id)\n",
    "            return answer1_idx\n",
    "\n",
    "\n",
    "def prepare_dataset(conversations_path):\n",
    "    with open(conversations_path, \"r\") as data:\n",
    "        conversations = json.load(data)\n",
    "    print(\"%d conversations loaded\"%len(conversations))\n",
    "    \n",
    "    max_triples = 50000000\n",
    "    offset = 0\n",
    "\n",
    "    # collect only samples where the answer is entity and it is adjacent to the seed entity\n",
    "    train_dataset = []\n",
    "\n",
    "    graph_sizes = []\n",
    "    max_n_edges = 2409 # max size of the graph allowed in the number of edges\n",
    "\n",
    "    for conversation in conversations[:10]:\n",
    "        question1 = conversation['questions'][0]['question']\n",
    "        # use oracle for the correct initial entity\n",
    "        seed_entity = conversation['seed_entity'].split('/')[-1]\n",
    "        seed_entity_id = kg.string_to_global_id(PREFIX_E+seed_entity, TripleComponentRole.OBJECT)\n",
    "\n",
    "        # retrieve all adjacent nodes including literals\n",
    "        subgraph1 = kg.compute_hops([seed_entity_id], max_triples, offset)\n",
    "        entity_ids, predicate_ids, adjacencies = subgraph1\n",
    "        assert len(predicate_ids) == len(adjacencies)\n",
    "#         print(\"conversation\")\n",
    "        # check that the answer is in the subgraph\n",
    "        answer1_idx = check_answer_in_subgraph(conversation, entity_ids)\n",
    "        if answer1_idx:\n",
    "            # get labels for all candidate predicates\n",
    "            p_labels_map = lookup_predicate_labels(predicate_ids)\n",
    "\n",
    "            # create a batch of samples for each predicate label separately\n",
    "            input_ids = []\n",
    "            attention_masks = []\n",
    "            token_type_ids = []\n",
    "            A = []\n",
    "\n",
    "            for p_label, p_ids in p_labels_map.items():\n",
    "\n",
    "                # encode a text pair of the question with a predicate label\n",
    "                encoded_dict = tokenizer.encode_plus(question1, p_label,\n",
    "                                                     add_special_tokens=True,\n",
    "                                                     max_length=64,\n",
    "                                                     pad_to_max_length=True,\n",
    "                                                     return_attention_mask=True,\n",
    "                                                     return_token_type_ids=True)\n",
    "                input_ids.append(encoded_dict['input_ids'])\n",
    "                token_type_ids.append(encoded_dict['token_type_ids'])\n",
    "                attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "                # get adjacencies only for the predicates sharing the same label\n",
    "                selected_adjacencies = []\n",
    "                for p_id in p_ids:\n",
    "                    p_id_idx = predicate_ids.index(p_id)\n",
    "                    # add all edges together\n",
    "                    for edge in adjacencies[p_id_idx]:\n",
    "                        if edge not in selected_adjacencies:\n",
    "                            selected_adjacencies.append(edge)\n",
    "                A.append(selected_adjacencies)\n",
    "\n",
    "            # create a single graph per example for all predicates\n",
    "            indices, relation_mask = adj(A, num_entities, num_relations)\n",
    "\n",
    "            train_dataset.append([torch.tensor(input_ids),\n",
    "                                  torch.tensor(token_type_ids),\n",
    "                                  torch.tensor(attention_masks),\n",
    "                                  [indices, relation_mask, entities],\n",
    "                                  torch.tensor([answer1_idx])])\n",
    "\n",
    "    print(\"Compiled dataset with %d samples\" % len(train_dataset))\n",
    "    return train_dataset\n",
    "\n",
    "train_dataset = prepare_dataset(train_conversations_path)\n",
    "valid_dataset = prepare_dataset(dev_conversations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setup\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "\n",
    "epochs = 4\n",
    "total_steps = len(train_dataset) * epochs\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
    "                 )\n",
    "# learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "9.44361686706543\n",
      "9.442474365234375\n",
      "9.442527770996094\n",
      "9.44200325012207\n",
      "8.65631103515625\n",
      "  Average training loss: 9.29\n",
      "\n",
      "Running Validation...\n",
      "8.259330749511719\n",
      "9.442011833190918\n",
      "9.442022323608398\n",
      "9.442011833190918\n",
      "9.442014694213867\n",
      "9.442037582397461\n",
      "9.442028999328613\n",
      "8.259330749511719\n",
      "  Validation Loss: 9.15\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "9.442057609558105\n",
      "9.44207763671875\n",
      "9.442155838012695\n",
      "9.442063331604004\n",
      "7.325770378112793\n",
      "  Average training loss: 9.02\n",
      "\n",
      "Running Validation...\n",
      "7.449199676513672\n",
      "9.442344665527344\n",
      "9.442366600036621\n",
      "9.442344665527344\n",
      "9.442349433898926\n",
      "9.442364692687988\n",
      "9.442363739013672\n",
      "7.449199676513672\n",
      "  Validation Loss: 8.94\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "9.442132949829102\n",
      "9.442344665527344\n",
      "9.442300796508789\n",
      "9.442259788513184\n",
      "7.1281232833862305\n",
      "  Average training loss: 8.98\n",
      "\n",
      "Running Validation...\n",
      "6.864914417266846\n",
      "9.442838668823242\n",
      "9.44283676147461\n",
      "9.442838668823242\n",
      "9.442821502685547\n",
      "9.442831039428711\n",
      "9.442846298217773\n",
      "6.864914417266846\n",
      "  Validation Loss: 8.80\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "9.442764282226562\n",
      "9.442649841308594\n",
      "9.442647933959961\n",
      "9.4427490234375\n",
      "6.711993217468262\n",
      "  Average training loss: 8.90\n",
      "\n",
      "Running Validation...\n",
      "6.649715900421143\n",
      "9.443066596984863\n",
      "9.443084716796875\n",
      "9.443066596984863\n",
      "9.443097114562988\n",
      "9.443079948425293\n",
      "9.443086624145508\n",
      "6.649715900421143\n",
      "  Validation Loss: 8.74\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# use CPU to train the model\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    \n",
    "    # reset the total loss for this epoch\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    # put the model into training mode\n",
    "    model.train()\n",
    "    \n",
    "    # for each sample of training data input as a batch of size 1\n",
    "    for step, batch in enumerate(train_dataset):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_token_mask = batch[1].to(device)\n",
    "        b_input_mask = batch[2].to(device)\n",
    "        b_graphs = [tensor.to(device) for tensor in batch[3]]\n",
    "        b_labels = batch[4].to(device)\n",
    "#         print(b_input_ids.shape)\n",
    "#         print(b_labels.shape)\n",
    "        model.zero_grad()\n",
    "        # forward pass\n",
    "        loss, logits = model(b_input_ids,\n",
    "                             b_graphs,\n",
    "                             token_type_ids=b_token_mask,\n",
    "                             attention_mask=b_input_mask,\n",
    "                             labels=b_labels)\n",
    "        print(loss.item())\n",
    "        # accumulate the training loss over all of the batches\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # clip gradient to prevent exploding\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # training epoch is over here\n",
    "    \n",
    "    # calculate average loss over all the batches\n",
    "    avg_train_loss = total_train_loss / len(train_dataset) \n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    \n",
    "    # put the model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    total_eval_loss = 0\n",
    "        \n",
    "    # evaluate data for one epoch\n",
    "    for step, batch in enumerate(valid_dataset):\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_token_mask = batch[1].to(device)\n",
    "        b_input_mask = batch[2].to(device)\n",
    "        b_graphs = [tensor.to(device) for tensor in batch[3]]\n",
    "        b_labels = batch[4].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # forward pass\n",
    "            loss, logits = model(b_input_ids,\n",
    "                                 b_graphs,\n",
    "                                 token_type_ids=b_token_mask,\n",
    "                                 attention_mask=b_input_mask,\n",
    "                                 labels=b_labels)\n",
    "            print(loss.item())\n",
    "            # accumulate validation loss\n",
    "            total_eval_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = total_eval_loss / len(valid_dataset)\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

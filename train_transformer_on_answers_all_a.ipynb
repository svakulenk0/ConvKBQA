{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Message-Passing Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "\n",
    "from MPBert_model import MessagePassingBert\n",
    "from utils import adj\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# model configuration\n",
    "model_name = 'bert-base-uncased'\n",
    "# 2 x 57942 in dev set need to be trimmed or sampled\n",
    "num_entities = 12605  # size of the output layer, i.e., maximum number of entities in the subgraph that are candidate answers\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# regression task for matching predicate/entity label to the input question\n",
    "config = BertConfig.from_pretrained(model_name, num_labels=1)\n",
    "\n",
    "model = MessagePassingBert(config, num_entities, mp_layer=True)\n",
    "# run model on the GPU\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52])\n",
      "torch.Size([2, 7])\n",
      "tensor(9.1537, grad_fn=<NllLossBackward>) tensor([ 0.0000,  0.2882, -0.1879,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# test inference with a sample input, where input is a question and a predicate label along with the list of edges for this predicate\n",
    "question1 = \"When were Beatles founded?\"\n",
    "output = 1\n",
    "\n",
    "# build input tensors\n",
    "input_ids = torch.tensor([tokenizer.encode(question1)] * num_relations)  # Batch size num_relations\n",
    "labels = torch.tensor([output]).unsqueeze(0)  # Batch size 1\n",
    "indices, relation_mask = adj(adjacencies, num_entities, num_relations)\n",
    "entities = torch.zeros(num_entities, 1)\n",
    "entities[[0, 3]] = 1\n",
    "print(relation_mask.shape)\n",
    "print(input_ids.shape)\n",
    "\n",
    "# run inference\n",
    "outputs = model(input_ids, [indices, relation_mask, entities], labels=labels)\n",
    "loss, logits = outputs[:2]\n",
    "print(loss, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.525114059448242\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model.train()\n",
    "outputs = model(input_ids, [indices, relation_mask, entities], labels=labels)\n",
    "loss = outputs[0]\n",
    "current_loss = loss.item()\n",
    "print(current_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load graph\n",
    "from hdt import HDTDocument, TripleComponentRole\n",
    "from settings import *\n",
    "\n",
    "hdt_file = 'wikidata2018_09_11.hdt'\n",
    "kg = HDTDocument(hdt_path+hdt_file)\n",
    "namespace = 'predef-wikidata2018-09-all'\n",
    "PREFIX_E = 'http://www.wikidata.org/entity/'\n",
    "\n",
    "# prepare to retrieve all adjacent nodes including literals\n",
    "predicates_ids = []\n",
    "kg.configure_hops(1, predicates_ids, namespace, True, False)\n",
    "\n",
    "# load all predicate labels\n",
    "from predicates import properties\n",
    "\n",
    "relationid2label = {}\n",
    "for p in properties['results']['bindings']:\n",
    "    _id = p['property']['value'].split('/')[-1]\n",
    "    label = p['propertyLabel']['value']\n",
    "    relationid2label[_id] = label\n",
    "\n",
    "# print(relationid2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6720 conversations loaded\n",
      "Compiled dataset with 70 samples\n",
      "2240 conversations loaded\n",
      "Compiled dataset with 67 samples\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "train_conversations_path = './data/train_set/train_set_ALL.json'\n",
    "dev_conversations_path = './data/dev_set/dev_set_ALL.json'\n",
    "\n",
    "\n",
    "def lookup_predicate_labels(predicate_ids):\n",
    "    p_labels_map = defaultdict(list)\n",
    "    for p_id in predicate_ids:\n",
    "        p_uri = kg.global_id_to_string(p_id, TripleComponentRole.PREDICATE)\n",
    "        label = p_uri.split('/')[-1]\n",
    "        if label in relationid2label:\n",
    "            label = relationid2label[label]\n",
    "        else:\n",
    "            label = label.split('#')[-1]\n",
    "        p_labels_map[label].append(p_id)\n",
    "    return p_labels_map\n",
    "\n",
    "\n",
    "def check_answer_in_subgraph(conversation, entity_ids):\n",
    "    answer1 = conversation['questions'][0]['answer']\n",
    "    # consider only answers which are entities\n",
    "    if ('www.wikidata.org' in answer1):\n",
    "        answer1_id = kg.string_to_global_id(PREFIX_E+answer1.split('/')[-1], TripleComponentRole.OBJECT)\n",
    "        in_subgraph = answer1_id in entity_ids\n",
    "        # consider only answer entities that are in the subgraph\n",
    "        if in_subgraph:\n",
    "            answer1_idx = entity_ids.index(answer1_id)\n",
    "            return answer1_idx\n",
    "\n",
    "\n",
    "def prepare_dataset(conversations_path, n_limit=100):\n",
    "    with open(conversations_path, \"r\") as data:\n",
    "        conversations = json.load(data)\n",
    "    print(\"%d conversations loaded\"%len(conversations))\n",
    "    \n",
    "    max_triples = 50000000\n",
    "    offset = 0\n",
    "\n",
    "    # collect only samples where the answer is entity and it is adjacent to the seed entity\n",
    "    train_dataset = []\n",
    "\n",
    "    graph_sizes = []\n",
    "    max_n_edges = 2409 # max size of the graph allowed in the number of edges\n",
    "    if n_limit:\n",
    "        conversations = conversations[:n_limit]\n",
    "    for conversation in conversations:\n",
    "        question1 = conversation['questions'][0]['question']\n",
    "        # use oracle for the correct initial entity\n",
    "        seed_entity = conversation['seed_entity'].split('/')[-1]\n",
    "        seed_entity_id = kg.string_to_global_id(PREFIX_E+seed_entity, TripleComponentRole.OBJECT)\n",
    "\n",
    "        # retrieve all adjacent nodes including literals\n",
    "        subgraph = kg.compute_hops([seed_entity_id], max_triples, offset)\n",
    "        entity_ids, predicate_ids, adjacencies = subgraph\n",
    "        \n",
    "        if not len(entity_ids) <= num_entities:\n",
    "#             print(len(entity_ids))\n",
    "            continue  # skip samples with large subgraphs\n",
    "        assert len(predicate_ids) == len(adjacencies)\n",
    "#         print(\"conversation\")\n",
    "        # check that the answer is in the subgraph\n",
    "        answer1_idx = check_answer_in_subgraph(conversation, entity_ids)\n",
    "        if answer1_idx:\n",
    "            # activate seed entity\n",
    "            entities = torch.zeros(num_entities, 1)\n",
    "            entities[[entity_ids.index(seed_entity_id)]] = 1\n",
    "            \n",
    "            # get labels for all candidate predicates\n",
    "            p_labels_map = lookup_predicate_labels(predicate_ids)\n",
    "\n",
    "            # create a batch of samples for each predicate label separately\n",
    "            input_ids = []\n",
    "            attention_masks = []\n",
    "            token_type_ids = []\n",
    "            A = []\n",
    "\n",
    "            for p_label, p_ids in p_labels_map.items():\n",
    "\n",
    "                # encode a text pair of the question with a predicate label\n",
    "                encoded_dict = tokenizer.encode_plus(question1, p_label,\n",
    "                                                     add_special_tokens=True,\n",
    "                                                     max_length=64,\n",
    "                                                     pad_to_max_length=True,\n",
    "                                                     return_attention_mask=True,\n",
    "                                                     return_token_type_ids=True)\n",
    "                input_ids.append(encoded_dict['input_ids'])\n",
    "                token_type_ids.append(encoded_dict['token_type_ids'])\n",
    "                attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "                # get adjacencies only for the predicates sharing the same label\n",
    "                selected_adjacencies = []\n",
    "                for p_id in p_ids:\n",
    "                    p_id_idx = predicate_ids.index(p_id)\n",
    "                    # add all edges together\n",
    "                    for edge in adjacencies[p_id_idx]:\n",
    "                        if edge not in selected_adjacencies:\n",
    "                            selected_adjacencies.append(edge)\n",
    "                A.append(selected_adjacencies)\n",
    "\n",
    "            # create a single graph per example for all predicates\n",
    "            indices, relation_mask = adj(A, num_entities, num_relations)\n",
    "\n",
    "            train_dataset.append([torch.tensor(input_ids),\n",
    "                                  torch.tensor(token_type_ids),\n",
    "                                  torch.tensor(attention_masks),\n",
    "                                  [indices, relation_mask, entities],\n",
    "                                  torch.tensor([answer1_idx])])\n",
    "\n",
    "    print(\"Compiled dataset with %d samples\" % len(train_dataset))\n",
    "    return train_dataset\n",
    "\n",
    "train_dataset = prepare_dataset(train_conversations_path)\n",
    "valid_dataset = prepare_dataset(dev_conversations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setup\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "\n",
    "epochs = 4\n",
    "total_steps = len(train_dataset) * epochs\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n",
    "                 )\n",
    "# learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 training examples\n",
      "67 validation examples\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Average training loss: 8.31\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 8.95\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Average training loss: 7.98\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 7.74\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Average training loss: 6.56\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 6.13\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Average training loss: 5.40\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 6.37\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# use CPU to train the model\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"%d training examples\"%(len(train_dataset)))\n",
    "print(\"%d validation examples\"%(len(valid_dataset)))\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    \n",
    "    # reset the total loss for this epoch\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    # put the model into training mode\n",
    "    model.train()\n",
    "    \n",
    "    # for each sample of training data input as a batch of size 1\n",
    "    for step, batch in enumerate(train_dataset):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_token_mask = batch[1].to(device)\n",
    "        b_input_mask = batch[2].to(device)\n",
    "        b_graphs = [tensor.to(device) for tensor in batch[3]]\n",
    "        b_labels = batch[4].to(device)\n",
    "#         print(b_input_ids.shape)\n",
    "#         print(b_labels.shape)\n",
    "        model.zero_grad()\n",
    "        # forward pass\n",
    "        loss, logits = model(b_input_ids,\n",
    "                             b_graphs,\n",
    "                             token_type_ids=b_token_mask,\n",
    "                             attention_mask=b_input_mask,\n",
    "                             labels=b_labels)\n",
    "#         print(loss.item())\n",
    "        # accumulate the training loss over all of the batches\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # clip gradient to prevent exploding\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # training epoch is over here\n",
    "    \n",
    "    # calculate average loss over all the batches\n",
    "    avg_train_loss = total_train_loss / len(train_dataset) \n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    \n",
    "    # put the model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    total_eval_loss = 0\n",
    "        \n",
    "    # evaluate data for one epoch\n",
    "    for step, batch in enumerate(valid_dataset):\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_token_mask = batch[1].to(device)\n",
    "        b_input_mask = batch[2].to(device)\n",
    "        b_graphs = [tensor.to(device) for tensor in batch[3]]\n",
    "        b_labels = batch[4].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # forward pass\n",
    "            loss, logits = model(b_input_ids,\n",
    "                                 b_graphs,\n",
    "                                 token_type_ids=b_token_mask,\n",
    "                                 attention_mask=b_input_mask,\n",
    "                                 labels=b_labels)\n",
    "#             print(loss.item())\n",
    "            # accumulate validation loss\n",
    "            total_eval_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = total_eval_loss / len(valid_dataset)\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./saved_models/1_1stquestion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./saved_models/1_1stquestion/vocab.txt',\n",
       " './saved_models/1_1stquestion/special_tokens_map.json',\n",
       " './saved_models/1_1stquestion/added_tokens.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and load model\n",
    "import os\n",
    "\n",
    "output_dir = './saved_models/1_1stquestion'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n",
    "\n",
    "\n",
    "# Load a trained model and vocabulary that you have fine-tuned\n",
    "# model = MessagePassingBert.from_pretrained(output_dir)\n",
    "# tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "# Copy the model to the GPU.\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set P@1: 0.27\n",
      "Dev set P@1: 0.24\n"
     ]
    }
   ],
   "source": [
    "# run inference and evaluate performance on train and dev sets with the target QA metrics\n",
    "\n",
    "def run_inference(model, dataset):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # TODO add MRR\n",
    "    p1s = []  # measure accuracy of the top answer: P@1\n",
    "    for batch in dataset:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_token_mask = batch[1].to(device)\n",
    "        b_input_mask = batch[2].to(device)\n",
    "        b_graphs = [tensor.to(device) for tensor in batch[3]]\n",
    "        b_labels = batch[4].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # forward pass\n",
    "            loss, logits = model(b_input_ids,\n",
    "                                 b_graphs,\n",
    "                                 token_type_ids=b_token_mask,\n",
    "                                 attention_mask=b_input_mask,\n",
    "                                 labels=b_labels)\n",
    "            predicted_label = np.argmax(logits.numpy()).flatten()[0]\n",
    "#             print(predicted_label)\n",
    "            true_label = b_labels.numpy()[0]\n",
    "#             print(true_label)\n",
    "            p1 = int(predicted_label == true_label)\n",
    "#             print(p1)\n",
    "            p1s.append(p1)\n",
    "    \n",
    "    return p1s\n",
    "\n",
    "        \n",
    "p1s = run_inference(model, train_dataset)\n",
    "print(\"Train set P@1: %.2f\" % np.mean(p1s))\n",
    "\n",
    "p1s = run_inference(model, valid_dataset)\n",
    "print(\"Dev set P@1: %.2f\" % np.mean(p1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
